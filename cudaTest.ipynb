{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a79FXgRuRz4Z"
      },
      "outputs": [],
      "source": [
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.compiler as comp\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import numpy as np\n",
        "\n",
        "def matmul(a,b,length):\n",
        "    aRows = a.shape[0]\n",
        "    aCols = a.shape[1]\n",
        "    bCols = b.shape[1]\n",
        "    a_g = cuda.mem_alloc(a.nbytes)\n",
        "    cuda.memcpy_htod(a_g,a)\n",
        "    b_g = cuda.mem_alloc(b.nbytes)\n",
        "    cuda.memcpy_htod(b_g,b)\n",
        "    res_np = np.empty([aRows, bCols]).astype(np.float32).flatten()\n",
        "    res_g = cuda.mem_alloc(aRows * bCols * 4)\n",
        "    cuda.memcpy_htod(res_g,res_np)\n",
        "\n",
        "    mod = comp.SourceModule(\n",
        "      \"\"\"\n",
        "    __global__ void matmul(float *a, float *b, int aRows, int aCols, int bCols, float *res)\n",
        "  {\n",
        "    const int gid = threadIdx.x + (blockDim.x * blockIdx.x);\n",
        "    int row = gid / bCols;\n",
        "    int col = gid % bCols;\n",
        "    float total = 0;\n",
        "    if(row < aRows && col < bCols) \n",
        "    {\n",
        "      for(int i = 0; i < aCols; i++)\n",
        "      {\n",
        "        total += a[row * aCols + i] * b[col + i * bCols];\n",
        "      }\n",
        "      res[row * bCols + col] = total;\n",
        "    }\n",
        "  }\n",
        "  \"\"\"\n",
        "  )\n",
        "    matmulcuda = mod.get_function(\"matmul\")\n",
        "    numberOfThreads = \\\n",
        "        cuda.Device(0).get_attribute(pycuda._driver.device_attribute.MAX_THREADS_PER_BLOCK)\n",
        "    matmulcuda(a_g,b_g,np.int32(aRows),np.int32(aCols),np.int32(bCols),res_g,block=(1024,1,1),grid=(1024,1)) #todo fix these sizes\n",
        "    cuda.memcpy_dtoh(res_np,res_g)\n",
        "    return res_np"
      ],
      "metadata": {
        "id": "YG6MtwtWbcVe"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length = 128\n",
        "\n",
        "a = np.random.rand(200,length).astype(np.float32)\n",
        "b = np.random.rand(length,190).astype(np.float32)\n",
        "answer = np.matmul(a,b).flatten()\n",
        "output = matmul(a,b,length)\n",
        "print(output,answer)\n",
        "assert np.allclose(output, answer)\n",
        "print(\"passed\")"
      ],
      "metadata": {
        "id": "y9BdlCm-d4lS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}