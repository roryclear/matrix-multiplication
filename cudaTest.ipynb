{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a79FXgRuRz4Z"
      },
      "outputs": [],
      "source": [
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.compiler as comp\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import numpy as np\n",
        "\n",
        "def matmul(a,b,length):\n",
        "    a_g = cuda.mem_alloc(a.nbytes)\n",
        "    cuda.memcpy_htod(a_g,a)\n",
        "    b_g = cuda.mem_alloc(b.nbytes)\n",
        "    cuda.memcpy_htod(b_g,b)\n",
        "    res_g = cuda.mem_alloc(a.nbytes)\n",
        "    res_np = np.empty_like(a)#fix later\n",
        "    cuda.memcpy_htod(res_g,res_np)\n",
        "\n",
        "    mod = comp.SourceModule(\n",
        "      \"\"\"\n",
        "    __global__ void matmul(float *a, float *b, int length, float *res)\n",
        "  {\n",
        "    const int gid = threadIdx.x + (blockDim.x * blockIdx.x);\n",
        "    int row = gid / length;\n",
        "    int col = gid % length;\n",
        "    float total = 0;\n",
        "    if(row < length && col < length) \n",
        "    {\n",
        "      for(int i = 0; i < length; i++)\n",
        "      {\n",
        "        total += a[row * length + i] * b[col + i * length];\n",
        "      }\n",
        "      res[row * length + col] = total;\n",
        "    }\n",
        "  }\n",
        "  \"\"\"\n",
        "  )\n",
        "    matmulcuda = mod.get_function(\"matmul\")\n",
        "    numberOfThreads = \\\n",
        "        cuda.Device(0).get_attribute(pycuda._driver.device_attribute.MAX_THREADS_PER_BLOCK)\n",
        "    matmulcuda(a_g,b_g,np.int32(length),res_g,block=(1024,1,1),grid=(16,1)) #todo fix these sizes\n",
        "    cuda.memcpy_dtoh(res_np,res_g)\n",
        "    return res_np"
      ],
      "metadata": {
        "id": "YG6MtwtWbcVe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length = 128\n",
        "size = length*length\n",
        "\n",
        "a = np.random.rand(size).astype(np.float32)\n",
        "b = np.random.rand(size).astype(np.float32)\n",
        "answer = np.empty_like(a)\n",
        "output = np.empty_like(a)\n",
        "\n",
        "for r in range(length):\n",
        "  for c in range(length):\n",
        "    total = 0\n",
        "    for n in range(length):\n",
        "      total += a[r * length + n] * b[c + n * length]\n",
        "    answer[r * length + c] = total\n",
        "\n",
        "output = matmul(a,b,length)\n",
        "assert np.allclose(output, answer)\n",
        "print(\"passed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9BdlCm-d4lS",
        "outputId": "3ef5659f-58cf-42c3-8c00-d0a5835f4140"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "passed\n"
          ]
        }
      ]
    }
  ]
}