{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WfGJQtzuCc6n"
      },
      "outputs": [],
      "source": [
        "import torch, gc\n",
        "import time\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# strassen CPU attempt\n",
        "\n",
        "a = torch.randn(2,2)\n",
        "b = torch.randn(2,2)\n",
        "\n",
        "# ------\n",
        "\n",
        "def naive(a,b):\n",
        "  n = int(len(a))\n",
        "  c = torch.zeros(n,n)\n",
        "\n",
        "  for y in range(n):\n",
        "    for x in range(n):\n",
        "      for z in range(n):\n",
        "        c[y][x] += a[y][z] * b[z][x]\n",
        "\n",
        "  return c\n",
        "\n",
        "\n",
        "def strassen2x2(a,b):\n",
        "  \n",
        "  m1 = (a[0][0] + a[1][1]) * (b[0][0] + b[1][1])\n",
        "  m2 = (a[1][0] + a[1][1]) * b[0][0]\n",
        "  m3 = a[0][0] * (b[0][1] - b[1][1])\n",
        "  m4 = a[1][1] * (b[1][0] - b[0][0])\n",
        "  m5 = (a[0][0] + a[0][1]) * b[1][1]\n",
        "  m6 = (a[1][0] - a[0][0]) * (b[0][0] + b[0][1])\n",
        "  m7 = (a[0][1] - a[1][1]) * (b[1][0] + b[1][1])\n",
        "  \n",
        "  return torch.tensor([[m1 + m4 - m5 + m7 , m3 + m5],\n",
        "                        [m2 + m4 , m1 - m2 + m3 + m6]])\n",
        "\n",
        "def strassen(a,b):\n",
        "\n",
        "  if a.size() == torch.Size([2, 2]):\n",
        "    return strassen2x2(a,b)\n",
        "\n",
        "  n = int(len(a))\n",
        "  n0 = n\n",
        "  x = math.ceil(math.log2(n))\n",
        "  newSize = int(math.pow(2,x))\n",
        "  if n != newSize:\n",
        "    a2 = torch.zeros(newSize,newSize)\n",
        "    b2 = torch.zeros(newSize,newSize)\n",
        "    a2[:n,:n] = a\n",
        "    b2[:n,:n] = b\n",
        "    a = a2\n",
        "    b = b2\n",
        "\n",
        "  n = int(newSize / 2)\n",
        "\n",
        "  a11 = a[:n,:n]\n",
        "  a12 = a[:n,n:]\n",
        "  a21 = a[n:,:n]\n",
        "  a22 = a[n:,n:]\n",
        "\n",
        "  b11 = b[:n,:n]\n",
        "  b12 = b[:n,n:]\n",
        "  b21 = b[n:,:n]\n",
        "  b22 = b[n:,n:]\n",
        "\n",
        "  m1 = strassen((a11 + a22) , (b11 + b22))\n",
        "  m2 = strassen((a21 + a22) , b11)\n",
        "  m3 = strassen(a11 , (b12 - b22))\n",
        "  m4 = strassen(a22 , (b21 - b11))\n",
        "  m5 = strassen((a11 + a12) , b22)\n",
        "  m6 = strassen((a21 - a11) , (b11 + b12))\n",
        "  m7 = strassen((a12 - a22) , (b21 + b22))\n",
        "\n",
        "  ret = torch.randn(n*2,n*2)\n",
        "  ret[:n,:n] = m1 + m4 - m5 + m7\n",
        "  ret[:n,n:] = m3 + m5\n",
        "  ret[n:,:n] = m2 + m4\n",
        "  ret[n:,n:] = m1 - m2 + m3 + m6\n",
        "\n",
        "  return ret[:n0,:n0]\n",
        "\n",
        "o1 = strassen(a,b)\n",
        "o2 = torch.matmul(a,b)\n",
        "\n",
        "for y in range(len(o1)):\n",
        "  for x in range(len(o1[y])):\n",
        "    assert(abs(o1[y][x].item() - o2[y][x].item()) < 0.000001)\n",
        "\n",
        "a = torch.randn(16,16)\n",
        "b = torch.randn(16,16)\n",
        "\n",
        "o1 = strassen(a,b)\n",
        "o2 = torch.matmul(a,b)\n",
        "o3 = naive(a,b)\n",
        "\n",
        "for y in range(len(o1)):\n",
        "  for x in range(len(o1[y])):\n",
        "    assert abs(o1[y][x].item() - o2[y][x].item()) < 0.0001 , (\"ffs\",o1[y][x].item(),o2[y][x].item())\n",
        "    assert abs(o3[y][x].item() - o2[y][x].item()) < 0.0001 , (\"ffs\",o3[y][x].item(),o2[y][x].item())\n",
        "\n",
        "\n",
        "a = torch.randn(20,20)\n",
        "b = torch.randn(20,20)\n",
        "\n",
        "o1 = strassen(a,b)\n",
        "o2 = torch.matmul(a,b)\n",
        "o3 = naive(a,b)\n",
        "\n",
        "for y in range(len(o1)):\n",
        "  for x in range(len(o1[y])):\n",
        "    assert abs(o1[y][x].item() - o2[y][x].item()) < 0.0001 , (\"ffs\",o1[y][x].item(),o2[y][x].item())\n",
        "    assert abs(o3[y][x].item() - o2[y][x].item()) < 0.0001 , (\"ffs\",o3[y][x].item(),o2[y][x].item())\n",
        "\n",
        "# SPEED TESTS\n",
        "\n",
        "n = 128\n",
        "a = torch.randn(n,n)\n",
        "b = torch.randn(n,n)\n",
        "\n",
        "start_time = time.time()\n",
        "o = torch.matmul(a,b)\n",
        "t = time.time() - start_time\n",
        "print(\"matmul \" + str(n) + \"x\" + str(n) + \" took\",t,\"seconds\")\n",
        "\n",
        "\n",
        "# NAIVE SPEED\n",
        "\n",
        "o = naive(a,b)\n",
        "t1 = time.time() - start_time\n",
        "print(\"naive \" + str(n) + \"x\" + str(n) + \" took\",t1,\"seconds\")\n",
        "\n",
        "n = int(n/2)\n",
        "a = torch.randn(n,n)\n",
        "b = torch.randn(n,n)\n",
        "\n",
        "start_time = time.time()\n",
        "o = naive(a,b)\n",
        "t2 = time.time() - start_time\n",
        "print(\"naive \" + str(n) + \"x\" + str(n) + \" took\",t2,\"seconds\")\n",
        "\n",
        "x = t1 / t2\n",
        "print(x,\"times slower\")\n",
        "\n",
        "p = math.log(x) / math.log(2)\n",
        "\n",
        "print(\"naive CPU -> n^\" + str(p) + \"\\n\\n\")\n",
        "\n",
        "# STRASSEN SPEED\n",
        "\n",
        "n = 128\n",
        "a = torch.randn(n,n)\n",
        "b = torch.randn(n,n)\n",
        "\n",
        "start_time = time.time()\n",
        "o = strassen(a,b)\n",
        "t1 = time.time() - start_time\n",
        "print(\"strassen \" + str(n) + \"x\" + str(n) + \" took\",t1,\"seconds\")\n",
        "\n",
        "n = int(n/2)\n",
        "a = torch.randn(n,n)\n",
        "b = torch.randn(n,n)\n",
        "\n",
        "start_time = time.time()\n",
        "o = strassen(a,b)\n",
        "t2 = time.time() - start_time\n",
        "print(\"strassen \" + str(n) + \"x\" + str(n) + \" took\",t2,\"seconds\")\n",
        "\n",
        "x = t1 / t2\n",
        "print(x,\"times slower\")\n",
        "\n",
        "p = math.log(x) / math.log(2)\n",
        "\n",
        "print(\"strassen CPU -> n^\" + str(p) + \"\\n\\n\")"
      ],
      "metadata": {
        "id": "gUCI32b-glGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pytorch CPU\n",
        "\n",
        "n = 8000\n",
        "m1 = torch.randn(n,n)\n",
        "m2 = torch.randn(n,n)\n",
        "r = torch.randn(n,n)\n",
        "\n",
        "start_time = time.time()\n",
        "r = torch.matmul(m1,m2)\n",
        "\n",
        "t1 = time.time() - start_time\n",
        "print(\"pytorch CPU time \"+str(n)+\"x\"+str(n),t1)\n",
        "\n",
        "n = int(n/2)\n",
        "m1 = torch.randn(n,n)\n",
        "m2 = torch.randn(n,n)\n",
        "r = torch.randn(n,n)\n",
        "\n",
        "start_time = time.time()\n",
        "r = torch.matmul(m1,m2)\n",
        "\n",
        "t2 = time.time() - start_time\n",
        "print(\"pytorch CPU time \"+str(n)+\"x\"+str(n),t2)\n",
        "\n",
        "x = t1 / t2\n",
        "print(x,\"times slower\")\n",
        "\n",
        "p = math.log(x) / math.log(2)\n",
        "\n",
        "print(\"pytorch CPU -> n^\" + str(p) + \"\\n\\n\")\n",
        "\n",
        "#pytorch GPU\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "n = 24000\n",
        "m1 = torch.randn(n,n).to(device)\n",
        "m2 = torch.randn(n,n).to(device)\n",
        "r = torch.randn(n,n).to(device)\n",
        "\n",
        "start_time = time.time()\n",
        "r = torch.matmul(m1,m2)\n",
        "\n",
        "torch.cuda.synchronize()\n",
        "t1 = time.time() - start_time\n",
        "print(\"pytorch GPU time \"+str(n)+\"x\"+str(n),t1)\n",
        "\n",
        "n = int(n/2)\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "m1 = torch.randn(n,n).to(device)\n",
        "m2 = torch.randn(n,n).to(device)\n",
        "r = torch.randn(n,n).to(device)\n",
        "\n",
        "start_time = time.time()\n",
        "r = torch.matmul(m1,m2)\n",
        "\n",
        "torch.cuda.synchronize()\n",
        "t2 = time.time() - start_time\n",
        "print(\"pytorch GPU time \"+str(n)+\"x\"+str(n),t2)\n",
        "\n",
        "x = t1 / t2\n",
        "print(x,\"times slower\")\n",
        "\n",
        "p = math.log(x) / math.log(2)\n",
        "\n",
        "print(\"pytorch GPU -> n^\" + str(p))"
      ],
      "metadata": {
        "id": "IG1RX5icCpqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda"
      ],
      "metadata": {
        "id": "qQQbhdQtxsGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MY OWN CUDA ATTEMPT\n",
        "import pycuda.compiler as comp\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "\n",
        "mod = comp.SourceModule(\n",
        "    \"\"\"\n",
        "  __global__ void matmul(float *nodesD, float *weights, float *nodesA, int ncA, int ncB, int nrA, int startn0, int startD, int startW)\n",
        "{\n",
        "  int row = threadIdx.y + blockDim.y * blockIdx.y;\n",
        "  int col = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "  float t = 0;\n",
        "  if(col < ncB && row < nrA)\n",
        "  {\n",
        "  for(int i = 0; i < ncA; i++){\n",
        "    t += weights[startW + (row * ncA) + i] * nodesA[startn0 + col + (i * ncB)];\n",
        "  }\n",
        "    nodesD[startD + (row * ncB) + col] = t;\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        ")\n",
        "MAX_THREADS_PER_BLOCK = \\\n",
        "    cuda.Device(0).get_attribute(pycuda._driver.device_attribute.MAX_THREADS_PER_BLOCK)\n",
        "cudaMatMul = mod.get_function(\"matmul\")\n",
        "\n",
        "\n",
        "n = 4\n",
        "m1 = torch.randn(n,n)\n",
        "m2 = torch.randn(n,n)\n",
        "r = torch.randn(n,n)\n",
        "\n",
        "r = torch.matmul(m1,m2)\n",
        "\n",
        "m1np = m1.numpy()\n",
        "m2np = m2.numpy()\n",
        "rnp = r.numpy()\n",
        "\n",
        "m1cuda = cuda.mem_alloc(m1np.nbytes)\n",
        "m2cuda = cuda.mem_alloc(m2np.nbytes)\n",
        "rcuda = cuda.mem_alloc(rnp.nbytes)\n",
        "\n",
        "cuda.memcpy_htod(m1cuda,m1np)\n",
        "cuda.memcpy_htod(m2cuda,m2np)\n",
        "cuda.memcpy_htod(rcuda,rnp)\n",
        "\n",
        "\n",
        "### check copy works ok\n",
        "cuda.memcpy_dtoh(rnp,rcuda)\n",
        "\n",
        "for y in range(len(rnp)):\n",
        "  for x in range(len(rnp[y])):\n",
        "    assert rnp[y][x] == r[y][x], \"copy didn't work\"\n"
      ],
      "metadata": {
        "id": "iBD4JA_ixkWX"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}