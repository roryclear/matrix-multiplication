{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WfGJQtzuCc6n"
      },
      "outputs": [],
      "source": [
        "import torch, gc\n",
        "import time\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# strassen CPU attempt\n",
        "\n",
        "a = torch.randn(2,2)\n",
        "b = torch.randn(2,2)\n",
        "\n",
        "# ------\n",
        "\n",
        "def strassen2x2(a,b):\n",
        "  \n",
        "  m1 = (a[0][0] + a[1][1]) * (b[0][0] + b[1][1])\n",
        "  m2 = (a[1][0] + a[1][1]) * b[0][0]\n",
        "  m3 = a[0][0] * (b[0][1] - b[1][1])\n",
        "  m4 = a[1][1] * (b[1][0] - b[0][0])\n",
        "  m5 = (a[0][0] + a[0][1]) * b[1][1]\n",
        "  m6 = (a[1][0] - a[0][0]) * (b[0][0] + b[0][1])\n",
        "  m7 = (a[0][1] - a[1][1]) * (b[1][0] + b[1][1])\n",
        "  \n",
        "  return torch.tensor([[m1 + m4 - m5 + m7 , m3 + m5],\n",
        "                        [m2 + m4 , m1 - m2 + m3 + m6]])\n",
        "\n",
        "\n",
        "o1 = strassen2x2(a,b)\n",
        "o2 = torch.matmul(a,b)\n",
        "\n",
        "for y in range(len(o1)):\n",
        "  for x in range(len(o1[y])):\n",
        "    assert(abs(o1[y][x].item() - o2[y][x].item()) < 0.000001)"
      ],
      "metadata": {
        "id": "gUCI32b-glGH"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pytorch CPU\n",
        "\n",
        "n = 8000\n",
        "m1 = torch.randn(n,n)\n",
        "m2 = torch.randn(n,n)\n",
        "r = torch.randn(n,n)\n",
        "\n",
        "start_time = time.time()\n",
        "r = torch.matmul(m1,m2)\n",
        "\n",
        "t1 = time.time() - start_time\n",
        "print(\"pytorch CPU time \"+str(n)+\"x\"+str(n),t1)\n",
        "\n",
        "n = int(n/2)\n",
        "m1 = torch.randn(n,n)\n",
        "m2 = torch.randn(n,n)\n",
        "r = torch.randn(n,n)\n",
        "\n",
        "start_time = time.time()\n",
        "r = torch.matmul(m1,m2)\n",
        "\n",
        "t2 = time.time() - start_time\n",
        "print(\"pytorch CPU time \"+str(n)+\"x\"+str(n),t2)\n",
        "\n",
        "x = t1 / t2\n",
        "print(x,\"times slower\")\n",
        "\n",
        "p = math.log(x) / math.log(2)\n",
        "\n",
        "print(\"pytorch CPU -> n^\" + str(p) + \"\\n\\n\")\n",
        "\n",
        "#pytorch GPU\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "n = 24000\n",
        "m1 = torch.randn(n,n).to(device)\n",
        "m2 = torch.randn(n,n).to(device)\n",
        "r = torch.randn(n,n).to(device)\n",
        "\n",
        "start_time = time.time()\n",
        "r = torch.matmul(m1,m2)\n",
        "\n",
        "torch.cuda.synchronize()\n",
        "t1 = time.time() - start_time\n",
        "print(\"pytorch GPU time \"+str(n)+\"x\"+str(n),t1)\n",
        "\n",
        "n = int(n/2)\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "m1 = torch.randn(n,n).to(device)\n",
        "m2 = torch.randn(n,n).to(device)\n",
        "r = torch.randn(n,n).to(device)\n",
        "\n",
        "start_time = time.time()\n",
        "r = torch.matmul(m1,m2)\n",
        "\n",
        "torch.cuda.synchronize()\n",
        "t2 = time.time() - start_time\n",
        "print(\"pytorch GPU time \"+str(n)+\"x\"+str(n),t2)\n",
        "\n",
        "x = t1 / t2\n",
        "print(x,\"times slower\")\n",
        "\n",
        "p = math.log(x) / math.log(2)\n",
        "\n",
        "print(\"pytorch GPU -> n^\" + str(p))\n",
        "\n",
        "\n",
        "# strassen CPU attempt"
      ],
      "metadata": {
        "id": "IG1RX5icCpqI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}