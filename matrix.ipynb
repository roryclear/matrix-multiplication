{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WfGJQtzuCc6n"
      },
      "outputs": [],
      "source": [
        "import torch, gc\n",
        "import time\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# strassen CPU attempt\n",
        "\n",
        "a = torch.randn(2,2)\n",
        "b = torch.randn(2,2)\n",
        "\n",
        "# ------\n",
        "\n",
        "def naive(a,b):\n",
        "  n = int(len(a))\n",
        "  c = torch.zeros(n,n)\n",
        "\n",
        "  for y in range(n):\n",
        "    for x in range(n):\n",
        "      for z in range(n):\n",
        "        c[y][x] += a[y][z] * b[z][x]\n",
        "\n",
        "  return c\n",
        "\n",
        "\n",
        "def strassen2x2(a,b):\n",
        "  \n",
        "  m1 = (a[0][0] + a[1][1]) * (b[0][0] + b[1][1])\n",
        "  m2 = (a[1][0] + a[1][1]) * b[0][0]\n",
        "  m3 = a[0][0] * (b[0][1] - b[1][1])\n",
        "  m4 = a[1][1] * (b[1][0] - b[0][0])\n",
        "  m5 = (a[0][0] + a[0][1]) * b[1][1]\n",
        "  m6 = (a[1][0] - a[0][0]) * (b[0][0] + b[0][1])\n",
        "  m7 = (a[0][1] - a[1][1]) * (b[1][0] + b[1][1])\n",
        "  \n",
        "  return torch.tensor([[m1 + m4 - m5 + m7 , m3 + m5],\n",
        "                        [m2 + m4 , m1 - m2 + m3 + m6]])\n",
        "\n",
        "def strassen(a,b):\n",
        "\n",
        "  if a.size() == torch.Size([2, 2]):\n",
        "    return strassen2x2(a,b)\n",
        "\n",
        "  n = int(len(a) / 2)\n",
        "\n",
        "  a11 = a[:n,:n]\n",
        "  a12 = a[:n,n:]\n",
        "  a21 = a[n:,:n]\n",
        "  a22 = a[n:,n:]\n",
        "\n",
        "  b11 = b[:n,:n]\n",
        "  b12 = b[:n,n:]\n",
        "  b21 = b[n:,:n]\n",
        "  b22 = b[n:,n:]\n",
        "\n",
        "  m1 = strassen((a11 + a22) , (b11 + b22))\n",
        "  m2 = strassen((a21 + a22) , b11)\n",
        "  m3 = strassen(a11 , (b12 - b22))\n",
        "  m4 = strassen(a22 , (b21 - b11))\n",
        "  m5 = strassen((a11 + a12) , b22)\n",
        "  m6 = strassen((a21 - a11) , (b11 + b12))\n",
        "  m7 = strassen((a12 - a22) , (b21 + b22))\n",
        "\n",
        "  ret = torch.randn(n*2,n*2)\n",
        "  ret[:n,:n] = m1 + m4 - m5 + m7\n",
        "  ret[:n,n:] = m3 + m5\n",
        "  ret[n:,:n] = m2 + m4\n",
        "  ret[n:,n:] = m1 - m2 + m3 + m6\n",
        "\n",
        "  return ret\n",
        "\n",
        "o1 = strassen(a,b)\n",
        "o2 = torch.matmul(a,b)\n",
        "\n",
        "for y in range(len(o1)):\n",
        "  for x in range(len(o1[y])):\n",
        "    assert(abs(o1[y][x].item() - o2[y][x].item()) < 0.000001)\n",
        "\n",
        "a = torch.randn(16,16)\n",
        "b = torch.randn(16,16)\n",
        "\n",
        "o1 = strassen(a,b)\n",
        "o2 = torch.matmul(a,b)\n",
        "o3 = naive(a,b)\n",
        "\n",
        "for y in range(len(o1)):\n",
        "  for x in range(len(o1[y])):\n",
        "    assert abs(o1[y][x].item() - o2[y][x].item()) < 0.0001 , (\"ffs\",o1[y][x].item(),o2[y][x].item())\n",
        "    assert abs(o3[y][x].item() - o2[y][x].item()) < 0.0001 , (\"ffs\",o3[y][x].item(),o2[y][x].item())\n",
        "\n",
        "\n",
        "# SPEED TESTS\n",
        "\n",
        "n = 256\n",
        "a = torch.randn(n,n)\n",
        "b = torch.randn(n,n)\n",
        "\n",
        "start_time = time.time()\n",
        "o = torch.matmul(a,b)\n",
        "t = time.time() - start_time\n",
        "print(\"matmul \" + str(n) + \"x\" + str(n) + \" took\",t,\"seconds\")\n",
        "\n",
        "\n",
        "# NAIVE SPEED\n",
        "\n",
        "o = naive(a,b)\n",
        "t1 = time.time() - start_time\n",
        "print(\"naive \" + str(n) + \"x\" + str(n) + \" took\",t1,\"seconds\")\n",
        "\n",
        "n = int(n/2)\n",
        "a = torch.randn(n,n)\n",
        "b = torch.randn(n,n)\n",
        "\n",
        "start_time = time.time()\n",
        "o = naive(a,b)\n",
        "t2 = time.time() - start_time\n",
        "print(\"naive \" + str(n) + \"x\" + str(n) + \" took\",t2,\"seconds\")\n",
        "\n",
        "x = t1 / t2\n",
        "print(x,\"times slower\")\n",
        "\n",
        "p = math.log(x) / math.log(2)\n",
        "\n",
        "print(\"naive CPU -> n^\" + str(p) + \"\\n\\n\")\n",
        "\n",
        "# STRASSEN SPEED\n",
        "\n",
        "n = 256\n",
        "a = torch.randn(n,n)\n",
        "b = torch.randn(n,n)\n",
        "\n",
        "start_time = time.time()\n",
        "o = strassen(a,b)\n",
        "t1 = time.time() - start_time\n",
        "print(\"strassen \" + str(n) + \"x\" + str(n) + \" took\",t1,\"seconds\")\n",
        "\n",
        "n = int(n/2)\n",
        "a = torch.randn(n,n)\n",
        "b = torch.randn(n,n)\n",
        "\n",
        "start_time = time.time()\n",
        "o = strassen(a,b)\n",
        "t2 = time.time() - start_time\n",
        "print(\"strassen \" + str(n) + \"x\" + str(n) + \" took\",t2,\"seconds\")\n",
        "\n",
        "x = t1 / t2\n",
        "print(x,\"times slower\")\n",
        "\n",
        "p = math.log(x) / math.log(2)\n",
        "\n",
        "print(\"strassen CPU -> n^\" + str(p) + \"\\n\\n\")"
      ],
      "metadata": {
        "id": "gUCI32b-glGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pytorch CPU\n",
        "\n",
        "n = 8000\n",
        "m1 = torch.randn(n,n)\n",
        "m2 = torch.randn(n,n)\n",
        "r = torch.randn(n,n)\n",
        "\n",
        "start_time = time.time()\n",
        "r = torch.matmul(m1,m2)\n",
        "\n",
        "t1 = time.time() - start_time\n",
        "print(\"pytorch CPU time \"+str(n)+\"x\"+str(n),t1)\n",
        "\n",
        "n = int(n/2)\n",
        "m1 = torch.randn(n,n)\n",
        "m2 = torch.randn(n,n)\n",
        "r = torch.randn(n,n)\n",
        "\n",
        "start_time = time.time()\n",
        "r = torch.matmul(m1,m2)\n",
        "\n",
        "t2 = time.time() - start_time\n",
        "print(\"pytorch CPU time \"+str(n)+\"x\"+str(n),t2)\n",
        "\n",
        "x = t1 / t2\n",
        "print(x,\"times slower\")\n",
        "\n",
        "p = math.log(x) / math.log(2)\n",
        "\n",
        "print(\"pytorch CPU -> n^\" + str(p) + \"\\n\\n\")\n",
        "\n",
        "#pytorch GPU\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "n = 24000\n",
        "m1 = torch.randn(n,n).to(device)\n",
        "m2 = torch.randn(n,n).to(device)\n",
        "r = torch.randn(n,n).to(device)\n",
        "\n",
        "start_time = time.time()\n",
        "r = torch.matmul(m1,m2)\n",
        "\n",
        "torch.cuda.synchronize()\n",
        "t1 = time.time() - start_time\n",
        "print(\"pytorch GPU time \"+str(n)+\"x\"+str(n),t1)\n",
        "\n",
        "n = int(n/2)\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "m1 = torch.randn(n,n).to(device)\n",
        "m2 = torch.randn(n,n).to(device)\n",
        "r = torch.randn(n,n).to(device)\n",
        "\n",
        "start_time = time.time()\n",
        "r = torch.matmul(m1,m2)\n",
        "\n",
        "torch.cuda.synchronize()\n",
        "t2 = time.time() - start_time\n",
        "print(\"pytorch GPU time \"+str(n)+\"x\"+str(n),t2)\n",
        "\n",
        "x = t1 / t2\n",
        "print(x,\"times slower\")\n",
        "\n",
        "p = math.log(x) / math.log(2)\n",
        "\n",
        "print(\"pytorch GPU -> n^\" + str(p))\n",
        "\n",
        "\n",
        "# strassen CPU attempt"
      ],
      "metadata": {
        "id": "IG1RX5icCpqI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}